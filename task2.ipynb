{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2cfe65-5f63-4ed7-8303-c6add847632f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.11 environment at: /home/zeus/miniconda3/envs/cloudspace\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.11 environment at: /home/zeus/miniconda3/envs/cloudspace\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m39 packages\u001b[0m \u001b[2min 269ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 68ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K░░░░░░░░░░░░░░░░░░░░ [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mFailed to hardlink files; falling back to full copy. This may lead to degraded performance.\n",
      "         If the cache and target directories are on different filesystems, hardlinking may not be supported.\n",
      "         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 25ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.12.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install transformers datasets\n",
    "!uv pip install sentencepiece\n",
    "!uv pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f00c5-04f7-4592-9b52-a22951db6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip  \"Language Challenge.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91231775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                         TrainingArguments, DataCollatorWithPadding)\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import torch\n",
    "from transformers import Trainer\n",
    "from torch import nn\n",
    "from datasets import ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e90a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29873/3094735980.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv('Language Challenge/quora-question-pairs/test.csv')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Language Challenge/quora-question-pairs/train.csv')\n",
    "test = pd.read_csv('Language Challenge/quora-question-pairs/test.csv')\n",
    "\n",
    "train[\"question1\"] = train[\"question1\"].astype(str)\n",
    "train[\"question2\"] = train[\"question2\"].astype(str)\n",
    "\n",
    "test[\"question1\"] = test[\"question1\"].astype(str)\n",
    "test[\"question2\"] = test[\"question2\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba6d02a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.7926, 1.3543])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f29990a815144f482a80336549de24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/404290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834d7dec09c3433fa73946bd58ee01c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/404290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    \"balanced\",\n",
    "    classes=np.array([0, 1]),\n",
    "    y=train[\"is_duplicate\"].values\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"question1\"],\n",
    "        examples[\"question2\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=350\n",
    "    )\n",
    "\n",
    "# Convert to HF dataset\n",
    "dataset = Dataset.from_pandas(train[[\"question1\", \"question2\", \"is_duplicate\"]])\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "dataset = dataset.rename_column(\"is_duplicate\", \"labels\")\n",
    "dataset = dataset.cast_column(\"labels\", ClassLabel(names=['non_duplicate', 'duplicate']))\n",
    "\n",
    "split_dataset = dataset.train_test_split(\n",
    "    test_size=0.1, \n",
    "    stratify_by_column=\"labels\",\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_29873/1255542706.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11372' max='11372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11372/11372 1:13:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.270286</td>\n",
       "      <td>0.858170</td>\n",
       "      <td>0.879910</td>\n",
       "      <td>0.781291</td>\n",
       "      <td>0.951829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.221934</td>\n",
       "      <td>0.880331</td>\n",
       "      <td>0.901203</td>\n",
       "      <td>0.827497</td>\n",
       "      <td>0.940373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.229015</td>\n",
       "      <td>0.885843</td>\n",
       "      <td>0.906327</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.937358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.221047</td>\n",
       "      <td>0.889842</td>\n",
       "      <td>0.910265</td>\n",
       "      <td>0.852288</td>\n",
       "      <td>0.930859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11372, training_loss=0.22155164582101217, metrics={'train_runtime': 4383.5639, 'train_samples_per_second': 166.011, 'train_steps_per_second': 2.594, 'total_flos': 2.165844790637431e+16, 'train_loss': 0.22155164582101217, 'epoch': 2.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False,num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), \n",
    "                       labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-base\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deberta-tuned-task2\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,  \n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=2500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=2500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_steps=100,\n",
    "    warmup_steps=500, \n",
    "    fp16=True\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        'f1': f1_score(labels, predictions, average='binary'),\n",
    "        'f1_macro': f1_score(labels, predictions, average='macro'),\n",
    "        'precision': precision_score(labels, predictions),\n",
    "        'recall': recall_score(labels, predictions),\n",
    "    }\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.class_weights = class_weights.to(trainer.args.device)\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06369b8e-62a3-47c0-b68a-b6d258756185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from 'deberta-tuned-task2/checkpoint-11372' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): DebertaV2ForSequenceClassification(\n",
       "    (deberta): DebertaV2Model(\n",
       "      (embeddings): DebertaV2Embeddings(\n",
       "        (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): DebertaV2Encoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x DebertaV2Layer(\n",
       "            (attention): DebertaV2Attention(\n",
       "              (self): DisentangledSelfAttention(\n",
       "                (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): DebertaV2SelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): DebertaV2Intermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): DebertaV2Output(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (rel_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (pooler): ContextPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MODEL_DIR = \"deberta-task2\"   \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)  \n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)  \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12cc3fb-db80-49a9-acb1-7dafd843f0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4123ed0a90499fa2ca09a9b3218847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/404290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1580 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:282: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "W0112 09:25:09.385000 29873 /system/conda/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
      "100%|██████████| 1580/1580 [22:43<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = train  \n",
    "\n",
    "test_ds = Dataset.from_pandas(test_df[[\"question1\", \"question2\"]])\n",
    "\n",
    "def tok_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"question1\"],\n",
    "        batch[\"question2\"],\n",
    "        truncation=True,          \n",
    "        max_length=350,           \n",
    "    )\n",
    "\n",
    "test_ds = test_ds.map(\n",
    "    tok_fn,\n",
    "    batched=True,\n",
    "    remove_columns=[\"question1\", \"question2\"],  \n",
    ")\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "loader = DataLoader(test_ds, batch_size=256, shuffle=False, collate_fn=collator)\n",
    "\n",
    "all_logits = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        logits = model(**batch).logits\n",
    "        all_logits.append(logits.cpu())\n",
    "\n",
    "logits = torch.cat(all_logits, dim=0).numpy()\n",
    "probs = torch.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "\n",
    "pred_label = np.argmax(logits, axis=1)  \n",
    "p_duplicate = probs[:, 1]               \n",
    "\n",
    "test_df[\"pred_label\"] = pred_label\n",
    "test_df[\"p_duplicate\"] = p_duplicate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fada32e1-aca7-47a3-a228-5d0471efa073",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_df[[\"id\", \"pred_label\"]].copy()\n",
    "submission.columns = [\"id\", \"prediction\"]\n",
    "submission.to_csv(\"task2_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6189a-0565-4f2b-bfcf-71da5b65ee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8906495184763545\n",
      "Recall: 0.9696642838479731\n",
      "F1: 0.9284788689025173\n"
     ]
    }
   ],
   "source": [
    "y_true = train[\"is_duplicate\"].values\n",
    "y_pred = train[\"pred_label\"].values\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495df05a-96d7-465b-b0ab-9fb446c8b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0\n",
      "Best F1: 0.9307837363513659\n",
      "Best Precision: 0.9086396120469628\n",
      "Best Recall: 0.9540341544790069\n"
     ]
    }
   ],
   "source": [
    "y_true = train[\"is_duplicate\"].values\n",
    "probs = train[\"p_duplicate\"].values\n",
    "\n",
    "best_f1 = 0\n",
    "best_t = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "for t in np.linspace(0.05, 0.95, 50):\n",
    "    f1 = f1_score(y_true, probs > t)\n",
    "    precision = precision_score(y_true, probs > t)\n",
    "    recall = recall_score(y_true, probs > t)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "\n",
    "print(\"Best threshold:\", best_t)\n",
    "print(\"Best F1:\", best_f1)\n",
    "print(\"Best Precision:\", best_precision)\n",
    "print(\"Best Recall:\", best_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903537f2-178c-4841-8802-2924577eb01b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
